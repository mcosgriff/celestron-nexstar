"""add_space_events_table

Revision ID: 030d966a662d
Revises: 623f166524aa
Create Date: 2025-11-09 19:21:40.515011

"""

import contextlib
from collections.abc import Sequence

import sqlalchemy as sa

from alembic import op


# revision identifiers, used by Alembic.
revision: str = "030d966a662d"
down_revision: str | Sequence[str] | None = "623f166524aa"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Check if table already exists (for databases created before migrations)
    conn = op.get_bind()
    inspector = sa.inspect(conn)
    existing_tables = inspector.get_table_names()

    if "space_events" not in existing_tables:
        op.create_table(
            "space_events",
            sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
            sa.Column("name", sa.String(length=255), nullable=False),
            sa.Column("event_type", sa.String(length=50), nullable=False),
            sa.Column("date", sa.DateTime(timezone=True), nullable=False),
            sa.Column("description", sa.Text(), nullable=False),
            sa.Column("min_latitude", sa.Float(), nullable=True),
            sa.Column("max_latitude", sa.Float(), nullable=True),
            sa.Column("min_longitude", sa.Float(), nullable=True),
            sa.Column("max_longitude", sa.Float(), nullable=True),
            sa.Column("dark_sky_required", sa.Boolean(), nullable=False),
            sa.Column("min_bortle_class", sa.Integer(), nullable=True),
            sa.Column("equipment_needed", sa.String(length=50), nullable=True),
            sa.Column("viewing_notes", sa.Text(), nullable=True),
            sa.Column("source", sa.String(length=100), nullable=False),
            sa.Column("url", sa.String(length=500), nullable=True),
            sa.Column("created_at", sa.DateTime(timezone=True), nullable=False),
            sa.Column("updated_at", sa.DateTime(timezone=True), nullable=False),
            sa.PrimaryKeyConstraint("id"),
        )
    else:
        # Table exists, skip creation but ensure indexes exist
        pass

    # Create indexes (check if they exist first)
    with op.batch_alter_table("space_events", schema=None) as batch_op:
        batch_op.create_index("idx_event_date_type", ["date", "event_type"], unique=False)
        batch_op.create_index(batch_op.f("ix_space_events_date"), ["date"], unique=False)
        batch_op.create_index(batch_op.f("ix_space_events_event_type"), ["event_type"], unique=False)
        batch_op.create_index(batch_op.f("ix_space_events_name"), ["name"], unique=False)

    # Drop FTS tables if they exist (may not exist in all databases)
    conn = op.get_bind()
    inspector = sa.inspect(conn)
    existing_tables = inspector.get_table_names()

    # FTS5 creates these internal tables automatically - only drop if they exist
    fts_tables = [
        "objects_fts",
        "objects_fts_config",
        "objects_fts_data",
        "objects_fts_idx",
        "objects_fts_docsize",
    ]

    for fts_table in fts_tables:
        if fts_table in existing_tables:
            with contextlib.suppress(Exception):
                # Ignore errors - table might be locked or already dropped
                op.execute(f"DROP TABLE IF EXISTS {fts_table}")

    # Drop light_pollution_grid if it exists
    if "light_pollution_grid" in existing_tables:
        with op.batch_alter_table("light_pollution_grid", schema=None) as batch_op:
            if "idx_lp_lat_lon" in [idx["name"] for idx in inspector.get_indexes("light_pollution_grid")]:
                batch_op.drop_index(batch_op.f("idx_lp_lat_lon"))
            if "idx_lp_region" in [idx["name"] for idx in inspector.get_indexes("light_pollution_grid")]:
                batch_op.drop_index(batch_op.f("idx_lp_region"))
        op.drop_table("light_pollution_grid")
    # Create indexes on iss_passes if they don't exist (may have been created by a1b2c3d4e5f6)
    if "iss_passes" in existing_tables:
        existing_indexes = [idx["name"] for idx in inspector.get_indexes("iss_passes")]
        indexes_to_create = [
            ("idx_location_fetched", ["latitude", "longitude", "fetched_at"]),
            ("idx_location_rise_time", ["latitude", "longitude", "rise_time"]),
            ("ix_iss_passes_fetched_at", ["fetched_at"]),
            ("ix_iss_passes_latitude", ["latitude"]),
            ("ix_iss_passes_longitude", ["longitude"]),
            ("ix_iss_passes_rise_time", ["rise_time"]),
        ]

        for index_name, columns in indexes_to_create:
            if index_name not in existing_indexes:
                try:
                    columns_str = ", ".join(columns)
                    op.execute(f"CREATE INDEX IF NOT EXISTS {index_name} ON iss_passes ({columns_str})")
                except Exception:
                    # Index might have been created, ignore
                    pass

    with op.batch_alter_table("objects", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("idx_common_name"))
        batch_op.create_index(batch_op.f("ix_objects_common_name"), ["common_name"], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("objects", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_objects_common_name"))
        batch_op.create_index(batch_op.f("idx_common_name"), ["common_name"], unique=False)

    with op.batch_alter_table("iss_passes", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_iss_passes_rise_time"))
        batch_op.drop_index(batch_op.f("ix_iss_passes_longitude"))
        batch_op.drop_index(batch_op.f("ix_iss_passes_latitude"))
        batch_op.drop_index(batch_op.f("ix_iss_passes_fetched_at"))
        batch_op.drop_index("idx_location_rise_time")
        batch_op.drop_index("idx_location_fetched")

    op.create_table(
        "light_pollution_grid",
        sa.Column("id", sa.INTEGER(), nullable=True),
        sa.Column("latitude", sa.REAL(), nullable=False),
        sa.Column("longitude", sa.REAL(), nullable=False),
        sa.Column("sqm_value", sa.REAL(), nullable=False),
        sa.Column("region", sa.TEXT(), nullable=True),
        sa.Column("created_at", sa.TEXT(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=True),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("latitude", "longitude"),
    )
    with op.batch_alter_table("light_pollution_grid", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("idx_lp_region"), ["region"], unique=False)
        batch_op.create_index(batch_op.f("idx_lp_lat_lon"), ["latitude", "longitude"], unique=False)

    op.create_table(
        "objects_fts_docsize",
        sa.Column("id", sa.INTEGER(), nullable=True),
        sa.Column("sz", sa.BLOB(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "objects_fts_idx",
        sa.Column("segid", sa.Text(), nullable=False),
        sa.Column("term", sa.Text(), nullable=False),
        sa.Column("pgno", sa.Integer(), nullable=True),
        sa.PrimaryKeyConstraint("segid", "term"),
    )
    op.create_table(
        "objects_fts_data",
        sa.Column("id", sa.INTEGER(), nullable=True),
        sa.Column("block", sa.BLOB(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "objects_fts_config",
        sa.Column("k", sa.Text(), nullable=False),
        sa.Column("v", sa.Text(), nullable=True),
        sa.PrimaryKeyConstraint("k"),
    )
    op.create_table(
        "objects_fts",
        sa.Column("name", sa.Text(), nullable=True),
        sa.Column("common_name", sa.Text(), nullable=True),
        sa.Column("description", sa.Text(), nullable=True),
    )
    with op.batch_alter_table("space_events", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_space_events_name"))
        batch_op.drop_index(batch_op.f("ix_space_events_event_type"))
        batch_op.drop_index(batch_op.f("ix_space_events_date"))
        batch_op.drop_index("idx_event_date_type")

    op.drop_table("space_events")
    # ### end Alembic commands ###
