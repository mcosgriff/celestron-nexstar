"""add_space_events_table

Revision ID: 030d966a662d
Revises: 623f166524aa
Create Date: 2025-11-09 19:21:40.515011

"""

from collections.abc import Sequence

import sqlalchemy as sa

from alembic import op


# revision identifiers, used by Alembic.
revision: str = "030d966a662d"
down_revision: str | Sequence[str] | None = "623f166524aa"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Check if table already exists (for databases created before migrations)
    conn = op.get_bind()
    inspector = sa.inspect(conn)
    existing_tables = inspector.get_table_names()

    if "space_events" not in existing_tables:
        op.create_table(
            "space_events",
            sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
            sa.Column("name", sa.String(length=255), nullable=False),
            sa.Column("event_type", sa.String(length=50), nullable=False),
            sa.Column("date", sa.DateTime(timezone=True), nullable=False),
            sa.Column("description", sa.Text(), nullable=False),
            sa.Column("min_latitude", sa.Float(), nullable=True),
            sa.Column("max_latitude", sa.Float(), nullable=True),
            sa.Column("min_longitude", sa.Float(), nullable=True),
            sa.Column("max_longitude", sa.Float(), nullable=True),
            sa.Column("dark_sky_required", sa.Boolean(), nullable=False),
            sa.Column("min_bortle_class", sa.Integer(), nullable=True),
            sa.Column("equipment_needed", sa.String(length=50), nullable=True),
            sa.Column("viewing_notes", sa.Text(), nullable=True),
            sa.Column("source", sa.String(length=100), nullable=False),
            sa.Column("url", sa.String(length=500), nullable=True),
            sa.Column("created_at", sa.DateTime(timezone=True), nullable=False),
            sa.Column("updated_at", sa.DateTime(timezone=True), nullable=False),
            sa.PrimaryKeyConstraint("id"),
        )
    else:
        # Table exists, skip creation but ensure indexes exist
        pass

    # Create indexes (check if they exist first)
    with op.batch_alter_table("space_events", schema=None) as batch_op:
        batch_op.create_index("idx_event_date_type", ["date", "event_type"], unique=False)
        batch_op.create_index(batch_op.f("ix_space_events_date"), ["date"], unique=False)
        batch_op.create_index(batch_op.f("ix_space_events_event_type"), ["event_type"], unique=False)
        batch_op.create_index(batch_op.f("ix_space_events_name"), ["name"], unique=False)

    # Drop FTS tables if they exist (may not exist in all databases)
    conn = op.get_bind()
    inspector = sa.inspect(conn)
    existing_tables = inspector.get_table_names()

    if "objects_fts" in existing_tables:
        op.drop_table("objects_fts")
    if "objects_fts_config" in existing_tables:
        op.drop_table("objects_fts_config")
    if "objects_fts_data" in existing_tables:
        op.drop_table("objects_fts_data")
    if "objects_fts_idx" in existing_tables:
        op.drop_table("objects_fts_idx")
    if "objects_fts_docsize" in existing_tables:
        op.drop_table("objects_fts_docsize")

    # Drop light_pollution_grid if it exists
    if "light_pollution_grid" in existing_tables:
        with op.batch_alter_table("light_pollution_grid", schema=None) as batch_op:
            if "idx_lp_lat_lon" in [idx["name"] for idx in inspector.get_indexes("light_pollution_grid")]:
                batch_op.drop_index(batch_op.f("idx_lp_lat_lon"))
            if "idx_lp_region" in [idx["name"] for idx in inspector.get_indexes("light_pollution_grid")]:
                batch_op.drop_index(batch_op.f("idx_lp_region"))
        op.drop_table("light_pollution_grid")
    with op.batch_alter_table("iss_passes", schema=None) as batch_op:
        batch_op.create_index("idx_location_fetched", ["latitude", "longitude", "fetched_at"], unique=False)
        batch_op.create_index("idx_location_rise_time", ["latitude", "longitude", "rise_time"], unique=False)
        batch_op.create_index(batch_op.f("ix_iss_passes_fetched_at"), ["fetched_at"], unique=False)
        batch_op.create_index(batch_op.f("ix_iss_passes_latitude"), ["latitude"], unique=False)
        batch_op.create_index(batch_op.f("ix_iss_passes_longitude"), ["longitude"], unique=False)
        batch_op.create_index(batch_op.f("ix_iss_passes_rise_time"), ["rise_time"], unique=False)

    with op.batch_alter_table("objects", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("idx_common_name"))
        batch_op.create_index(batch_op.f("ix_objects_common_name"), ["common_name"], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("objects", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_objects_common_name"))
        batch_op.create_index(batch_op.f("idx_common_name"), ["common_name"], unique=False)

    with op.batch_alter_table("iss_passes", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_iss_passes_rise_time"))
        batch_op.drop_index(batch_op.f("ix_iss_passes_longitude"))
        batch_op.drop_index(batch_op.f("ix_iss_passes_latitude"))
        batch_op.drop_index(batch_op.f("ix_iss_passes_fetched_at"))
        batch_op.drop_index("idx_location_rise_time")
        batch_op.drop_index("idx_location_fetched")

    op.create_table(
        "light_pollution_grid",
        sa.Column("id", sa.INTEGER(), nullable=True),
        sa.Column("latitude", sa.REAL(), nullable=False),
        sa.Column("longitude", sa.REAL(), nullable=False),
        sa.Column("sqm_value", sa.REAL(), nullable=False),
        sa.Column("region", sa.TEXT(), nullable=True),
        sa.Column("created_at", sa.TEXT(), server_default=sa.text("(CURRENT_TIMESTAMP)"), nullable=True),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("latitude", "longitude"),
    )
    with op.batch_alter_table("light_pollution_grid", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("idx_lp_region"), ["region"], unique=False)
        batch_op.create_index(batch_op.f("idx_lp_lat_lon"), ["latitude", "longitude"], unique=False)

    op.create_table(
        "objects_fts_docsize",
        sa.Column("id", sa.INTEGER(), nullable=True),
        sa.Column("sz", sa.BLOB(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "objects_fts_idx",
        sa.Column("segid", sa.NullType(), nullable=False),
        sa.Column("term", sa.NullType(), nullable=False),
        sa.Column("pgno", sa.NullType(), nullable=True),
        sa.PrimaryKeyConstraint("segid", "term"),
    )
    op.create_table(
        "objects_fts_data",
        sa.Column("id", sa.INTEGER(), nullable=True),
        sa.Column("block", sa.BLOB(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "objects_fts_config",
        sa.Column("k", sa.NullType(), nullable=False),
        sa.Column("v", sa.NullType(), nullable=True),
        sa.PrimaryKeyConstraint("k"),
    )
    op.create_table(
        "objects_fts",
        sa.Column("name", sa.NullType(), nullable=True),
        sa.Column("common_name", sa.NullType(), nullable=True),
        sa.Column("description", sa.NullType(), nullable=True),
    )
    with op.batch_alter_table("space_events", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_space_events_name"))
        batch_op.drop_index(batch_op.f("ix_space_events_event_type"))
        batch_op.drop_index(batch_op.f("ix_space_events_date"))
        batch_op.drop_index("idx_event_date_type")

    op.drop_table("space_events")
    # ### end Alembic commands ###
